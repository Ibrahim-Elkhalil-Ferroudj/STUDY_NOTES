{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d6a1253",
   "metadata": {},
   "source": [
    "## Importance of data in AI development\n",
    "Data is the backbone of AI, whether it's for training ML models, validating algorithms or depoloying AI systems. The quality and security of the data that the developers use directly impacts the AI solutions performance and reliability. However, with great power comes great responisibilites, the sensitive nature of the data used makes it a prime target for malicious avtivities.\n",
    "\n",
    "### Key points\n",
    "#### 1. Training data\n",
    "AI models learn from the data which they are trained on. If this data is compormised it can lead to biased, inaccurate or even harmful outputs.\n",
    "#### 2. Inference Data\n",
    "During deployment, AI systems process new data inputs to generate predictions or decisions. Ensuring the integrity of this data is crucial for maintaining trust in the AI systems.\n",
    "#### 3. Data sensitivty\n",
    "It's crucial to protect it such as ***Personal Identifiable Information*** to avoid severe legal and financial consequences.\n",
    "\n",
    "### Key risks\n",
    "#### 1. Data Breaches \n",
    "Unauthorized access can lead to private data exposure\n",
    "#### 2. Data poisonning \n",
    "Introducing false or misleading data causing AI to learn incorrect patterns\n",
    "\n",
    "### Key Practices\n",
    "#### 1. Data Encryption\n",
    "Encrypting the data both at rest and in transit ensures that even if intercepted it cannot be read without the right encryption key.\n",
    "***Implementation*** : Use strong encryption standards such as ***AES256*** for data storage and secure socket layer/transport layer security for data transmission to protect against unauthorized access\n",
    "\n",
    "#### 2. Access control\n",
    "Implementation of role-based access control and ***Multifactor authentification***.\n",
    "\n",
    "#### 3. Data annonymization and regular audits\n",
    "\n",
    "## Practice activity of auditing a ML system\n",
    "First revewing the code and identifying security vulnerabilities such as : \n",
    "- ***Data Validation and sanitization***: Is the input data validated or sanitized to prevent malicious input?\n",
    "- ***Input Validation***: Are there any checks on the input data to make sure it mets expected formats or values?\n",
    "- ***Random state and seed management***: Is the random state used securely to prevent model predictibility.\n",
    "- ***Model security***: Are there security measures to protect the model from tampering or unauthorized access\n",
    "- ***Encryption***:  Is sensitive data encrypted when transmitted or stored\n",
    "- ***Integrity checks***: Are there mechanisms to verify the integrity of the model when loading it from storage\n",
    "\n",
    "#### Review of flawed code block\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "\n",
    "# Load Dataset (Flaw : No data validation or sanitization)\n",
    "data = pd.read_csv('user_data.csv')\n",
    "\n",
    "# Solution, Validate input data \n",
    "def validate_data(df):\n",
    "    if df.isnull()values.all():\n",
    "        raise ValueError('Dataset contains null values, please clean data before processing')\n",
    "        # Additional validation checks can be added\n",
    "    return df\n",
    "\n",
    "# load validated data\n",
    "data = validate_data(pd.read_csv('user_data.csv'))\n",
    "\n",
    "\n",
    "# Split data into features and targets (Flaw : No input validation)\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Solution, validate the inputs\n",
    "X = validate_data(data.iloc[:, :-1])\n",
    "Y = validate_data(data.iloc[:, -1])\n",
    "\n",
    "# Split the data into training and testing sets (Flaw : Fixed random state)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 46)\n",
    "\n",
    "# Solution, Using a securely generated random state\n",
    "import os\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2, random_state = os.urandom(16))\n",
    "\n",
    "# Train a simple logistic regrssion (Flaw : No model security check)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to disk (Flaw : No encrypted model saving)\n",
    "filename = 'Finalized_model-sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# Solution, Encrypt the model before saving\n",
    "import cryptography.fernet\n",
    "key = cryptography.fernet.Fernet.generate_key()\n",
    "cipher = cryptography.fernet.Fernet(key)\n",
    "# Save the encrypted model to disk\n",
    "filename = 'Finalized_model.sav'\n",
    "encrypted_model = cipher.encrypt(pickle.dumps(model))\n",
    "with open(filename, 'wb') as f : \n",
    "    f.write(encrypted_model)\n",
    "\n",
    "\n",
    "# Load the model from disl for later use (Flaw : No integrity check)\n",
    "Loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = Loaded_model.scor(X_test, y_test)\n",
    "\n",
    "# Solution, Load the model and verify it's integrity\n",
    "import hashlib\n",
    "with open(filename, 'rb') as f :\n",
    "    encrypted_model = f.read()\n",
    "    decrypted_model = cipher.decrypt(encrypted_model)\n",
    "loaded_model = pickle.loads(decrypted_model)\n",
    "\n",
    "# Compute the hash of the loaded model and compare it to the original model\n",
    "Loaded_model_hash = hashlib.sha256(pickle.dumps(decrypted_model)).hexdigest()\n",
    "Original_model_hash = hashlib.sha256(pickle.dumps(model)).hexdigest()\n",
    "if Loaded_model_hash != Original_model_hash : \n",
    "    raise ValueError(\"Model intefrity check failed\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
